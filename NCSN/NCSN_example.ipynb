{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NCSN_example.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPjWrxnyTj10k7wqPGAQZee"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Model Define\n","### First, we defined the sigmas of perturbation distibutsions.\n","$$ q_{\\sigma}(x)=\\int p_{data}(t)\\mathcal(x \\vert t, \\sigma^2\\mathbf{I}), \\ \\ \\ \\ \\ \\ \\frac{\\sigma_{1}}{\\sigma_{2}}=\\frac{\\sigma_{2}}{\\sigma_{3}}=\\cdots=\\frac{\\sigma_{L-1}}{\\sigma_{L}} > 1$$\n"," <br>\n"," <br>\n","\n","### Then, conditional perturbation distribution is:\n","$$ q_{\\sigma}(\\tilde{x} \\vert x)=\\mathcal{N}(\\tilde{x} \\vert x, \\sigma^2\\mathbf{I}). \\ \\ \\text{In other word},\\ \\ \\ \\tilde{x}=x+\\sigma*z,\\ \\ where\\ \\ z\\sim\\mathcal{N}(0, \\mathbf{I})$$\n"," <br>\n"," <br>\n","\n","### And, we defined a score model dependent on time.\n","$$ \\mathbf{s}_{\\theta}(x_t, \\sigma) \\approx \\nabla_x \\log{q_\\sigma}(x)$$\n"," <br>\n"," <br>\n","\n","### If perturbation distributsions were defined by sigmas, then the score of perturbation distribution is:\n","$$ \\nabla_{\\tilde{x}}\\log q_{\\sigma}(\\tilde{x}\\vert{x})=-\\frac{(\\tilde{x}-x)}{\\sigma^2}=-\\frac{z}{\\sigma} $$\n"," <br>\n"," <br>\n","\n","### Then, we can used a objective function for Langevin dynamics.\n","\n","$$ \\mathcal{L}(\\theta, \\{ \\sigma_{i}\\}_{i=1}^L)=\\frac{1}{L}\\sum_{i=1}^L\\lambda({\\sigma_i})\\mathcal{l}(\\theta;\\sigma_i),\\ \\ \\ \n","where\\ \\ \\ \\mathcal{l}(\\theta;\\sigma_i)=\\frac{1}{2}\\mathbb{E}_{p_{data}(x)}\\mathbb{E}_{\\tilde{x}\\sim\\mathcal{N}(x,\\sigma^2\\mathbf{I})}[\\Vert \\mathbf{s}_{\\theta}(\\tilde{x}, \\sigma)+\\frac{\\tilde{x}-x}{\\sigma^2}\\Vert^2_2]\n","$$"],"metadata":{"id":"YTUdTLv6xV31"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import math\n","import matplotlib.pyplot as plt\n","import matplotlib.animation as animation\n","from scipy.ndimage.interpolation import rotate\n","import numpy as np\n","\n","from IPython.display import HTML\n","from IPython.display import clear_output\n","\n","class Model(nn.Module):\n","    def __init__(self, device, L, sigma_min, sigma_max, p=0.5):\n","        super().__init__()\n","        self.device = device\n","        self.sigmas = torch.exp(torch.linspace(start=math.log(sigma_max), end=math.log(sigma_min), steps = L)).to(device = device)\n","        \n","        self.linear_model1 = nn.Sequential(\n","            nn.Linear(2, 256),\n","            nn.Dropout(p),\n","            nn.GELU(),\n","            \n","\n","        )\n","        self.Embedding = nn.Embedding(L, 256)\n","        \n","        self.linear_model2 = nn.Sequential(\n","            nn.Linear(256, 512),\n","            nn.Dropout(p),\n","            nn.GELU(),\n","            \n","            nn.Linear(512, 512),\n","            nn.Dropout(p),\n","            nn.GELU(),\n","            \n","            nn.Linear(512, 2),\n","        )\n","        \n","        self.to(device = self.device)\n","        \n","\n","    def loss_fn(self, x, idx=None):\n","        scores, target, sigma = self.forward(x, idx=idx, get_target=True)\n","        \n","        target = target.view(target.shape[0], -1)\n","        scores = scores.view(scores.shape[0], -1)\n","\n","        \n","        losses = torch.square(scores - target).mean(dim=-1) * sigma.squeeze() ** 2\n","        return losses.mean(dim=0)\n","\n","        \n","    def forward(self, x, idx=None, get_target=False):\n","        if idx == None:\n","            idx = torch.randint(0, len(self.sigmas), (x.size(0),)).to(device = self.device)\n","            used_sigmas = self.sigmas[idx][:,None]\n","            noise = torch.randn_like(x)\n","            x = x + noise * used_sigmas\n","            \n","        else:\n","            idx = torch.cat([torch.Tensor([idx for _ in range(x.size(0))])]).long().to(device = self.device)\n","            used_sigmas = self.sigmas[idx][:,None]\n","\n","        if get_target:\n","            target = - 1 / used_sigmas * noise\n","\n","        output = self.linear_model1(x)\n","        embed = self.Embedding(idx)\n","        output = self.linear_model2(output + embed)\n","\n","        return (output, target, used_sigmas) if get_target else output"],"metadata":{"id":"59WoVhzbxWvx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# When sampling, we used Langevin dynamic\n","\n","$$\\tilde{x}_{t} = \\tilde{x}_{t-1}+\\frac{\\epsilon}{2}\\nabla_{x}{\\log}p(\\tilde{x}_{t-1})+\\sqrt{\\epsilon}z_{t}$$"],"metadata":{"id":"z7xlB7Xnxb1d"}},{"cell_type":"code","source":["class AnnealedLangevinDynamic():\n","    def __init__(self, sigma_min, sigma_max, L, T, score_fn, device, eps = 1e-1):\n","        self.process = torch.exp(torch.linspace(start=math.log(sigma_max), end=math.log(sigma_min), steps = L))\n","        self.step_size = eps * (self.process / self.process[-1] ) ** 2\n","        self.score_fn = score_fn\n","        self.T = T\n","        self.device = device\n","\n","    def _one_annealed_step_iteration(self, x, idx):\n","        self.score_fn.eval()\n","        z, step_size = torch.randn_like(x).to(device = self.device), self.step_size[idx]\n","        x = x + 0.5 * step_size * self.score_fn(x, idx) + torch.sqrt(step_size) * z\n","        return x\n","\n","    def _one_annealed_step(self, x, idx):\n","        for _ in range(self.T):\n","            x = self._one_annealed_step_iteration(x, idx)\n","        return x\n","\n","    def _one_diffusion_step(self, x):\n","        for idx in range(len(self.process)):\n","            x = self._one_annealed_step(x, idx)\n","            yield x\n","    \n","    @torch.no_grad()\n","    def sampling(self, sampling_number, only_final=False):\n","        sample = (torch.rand([sampling_number,2]).to(device = self.device) - 0.5)*2\n","        sampling_list = []\n","        \n","        final = None\n","        for sample in self._one_diffusion_step(sample):\n","            final = sample\n","            if not only_final:\n","                sampling_list.append(final)\n","                \n","\n","        return final if only_final else torch.stack(sampling_list)\n","\n"],"metadata":{"id":"HipgGs7QxZf4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class AverageMeter(object):\n","    def __init__(self, name, fmt=':f'):\n","        self.name = name\n","        self.fmt = fmt\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","    \n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self. count += n\n","        self.avg = self.sum / self.count\n","    \n","    def __str__(self):\n","        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n","        return fmtstr.format(**self.__dict__)\n","\n","\n","class ProgressMeter(object):\n","    def __init__(self, num_batches, meters, prefix=\"\"):\n","        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n","        self.meters = meters\n","        self.prefix = prefix\n","\n","    def display(self, batch):\n","        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n","        entries += [str(meter) for meter in self.meters]\n","        \n","        print('\\r' + '\\t'.join(entries), end = '')\n","\n","    def _get_batch_fmtstr(self, num_batches):\n","        num_digits = len(str(num_batches // 1))\n","        fmt = '{:' + str(num_digits) + 'd}'\n","        return '[' + fmt + '/' + fmt.format(num_batches) + ']'"],"metadata":{"id":"Q-GxTNDIxdds"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def scatter(sample, only_final, scatter_range = [-10, 10]):\n","    clear_output()\n","    if only_final:\n","        scatter = sample.detach().cpu().numpy()\n","        scatter_x, scatter_y = scatter[:,0], scatter[:,1]\n","        plt.figure(figsize=(7, 7))\n","\n","        plt.xlim(scatter_range)\n","        plt.ylim(scatter_range)\n","        plt.rc('axes', unicode_minus=False)\n","\n","        plt.scatter(scatter_x, scatter_y, s=5)\n","        plt.show()\n","    \n","    else:\n","        step_size = sample.size(0)\n","        fig, axs = plt.subplots(1, step_size, figsize=(step_size * 4, 4), constrained_layout = True)\n","        for i in range(step_size):\n","            scatter = sample[i].detach().cpu().numpy()\n","            scatter_x, scatter_y = scatter[:,0], scatter[:,1]\n","            axs[i].scatter(scatter_x, scatter_y, s=5)\n","            axs[i].set_xlim(scatter_range)\n","            axs[i].set_ylim(scatter_range)\n","        plt.show()"],"metadata":{"id":"moYPjXIqxet4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Example 1\n","\n","$$0.2 \\times \\mathcal{N}((3,3), I) + 0.8 \\times \\mathcal{N}((-3,-3), I)$$"],"metadata":{"id":"Lu9kARRIxh2b"}},{"cell_type":"code","source":["class DataSet(torch.utils.data.Dataset):\n","    def __init__(self, dist1, dist2, shape = (2), probability=0.2, total_len = 1000000):\n","        self.dist1_mean, self.dist1_var = dist1[0], dist1[1]\n","        self.dist2_mean, self.dist2_var = dist2[0], dist2[1]\n","        self.shape = shape\n","        self.probability = probability\n","        self.total_len = total_len\n","        \n","    @property\n","    def get_probability(self):\n","        return torch.rand(1) < self.probability\n","        \n","    @property\n","    def _sampling_1(self):\n","        return self.dist1_mean + torch.randn(self.shape) * self.dist1_var\n","\n","    @property\n","    def _sampling_2(self):\n","        return self.dist2_mean + torch.randn(self.shape) * self.dist2_var\n","\n","    def __len__(self):\n","        return self.total_len\n","    \n","    def __getitem__(self, idx):\n","        data = self._sampling_1 if self.get_probability else self._sampling_2\n","\n","        return data"],"metadata":{"id":"NecWlX-5xgA3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["eps = 1e-6\n","sigma_min = 0.001\n","sigma_max = 10\n","\n","L = 10\n","T = 100\n","\n","total_iteration = 1000\n","current_iteration = 0\n","display_iteration = 200\n","scatter_range = [-10, 10]\n","\n","batch_size = 8192 * 2\n","\n","dist1 = (3, 1)\n","dist2 = (-3, 1)\n","dataloader = torch.utils.data.DataLoader(DataSet(dist1, dist2, total_len=batch_size * total_iteration), batch_size = batch_size, drop_last = True)\n","\n","\n","sampling_number = 1000\n","device = torch.device('cuda')\n","only_final = True\n","\n","dataiterator = iter(dataloader)\n","\n","model = Model(device, L, sigma_min, sigma_max, p = 0.3)\n","optim = torch.optim.Adam(model.parameters(), lr = 0.005)\n","dynamic = AnnealedLangevinDynamic(sigma_min, sigma_max, L, T, model, device, eps=eps)"],"metadata":{"id":"equptitBxkLw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["scatter(next(iter(dataloader)), True)"],"metadata":{"id":"AEcUKlIpxlpC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["losses = AverageMeter('Loss', ':.4f')\n","progress = ProgressMeter(total_iteration, [losses], prefix='Iteration ')"],"metadata":{"id":"RH6kpillxoFr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["while current_iteration != total_iteration:\n","    try:\n","        data = dataiterator.next()\n","    except:\n","        dataiterator = iter(dataloader)\n","        data = dataiterator.next()\n","    data = data.to(device = device)\n","    loss = model.loss_fn(data)\n","\n","    optim.zero_grad()\n","    loss.backward()\n","    optim.step()\n","\n","    losses.update(loss.item())\n","    progress.display(current_iteration)\n","    \n","    current_iteration += 1\n","    \n","    if current_iteration % display_iteration == 0:\n","        dynamic = AnnealedLangevinDynamic(sigma_min, sigma_max, L, T, model, device, eps=eps)\n","        sample = dynamic.sampling(sampling_number, only_final)\n","        scatter(sample, only_final, scatter_range = scatter_range)\n","        losses.reset()\n"],"metadata":{"id":"Eeig3WpSxp4l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sampling_number = 1000\n","only_final = True\n","dynamic = AnnealedLangevinDynamic(sigma_min, sigma_max, L, T, model, device, eps=eps)\n","sample = dynamic.sampling(sampling_number, only_final)\n","scatter(sample, only_final, scatter_range= scatter_range)"],"metadata":{"id":"0Dyu7QqixrSG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["eps = 2e-6\n","sampling_number = 1000\n","only_final = False\n","dynamic = AnnealedLangevinDynamic(sigma_min, sigma_max, L, T, model, device, eps=eps)\n","sample = dynamic.sampling(sampling_number, only_final)\n","scatter(sample, only_final, scatter_range=scatter_range)"],"metadata":{"id":"dSHCf4Y1xs24"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def update_plot(i, data, scat):\n","    scat.set_offsets(data[i].detach().cpu().numpy())\n","    return scat\n","\n","numframes = len(sample)\n","scatter_point = sample[0].detach().cpu().numpy()\n","scatter_x, scatter_y = scatter_point[:,0], scatter_point[:,1]\n","\n","fig = plt.figure(figsize=(6, 6))\n","plt.xlim(scatter_range)\n","plt.ylim(scatter_range)\n","scat = plt.scatter(scatter_x, scatter_y, s=1)\n","plt.show()\n","clear_output()\n","\n","ani = animation.FuncAnimation(fig, update_plot, frames=range(numframes), fargs=(sample, scat), interval=150)\n","# ani.save('ncsn_toy.gif')\n","HTML(ani.to_jshtml())"],"metadata":{"id":"gSRbYQtnxuRU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Example 2"],"metadata":{"id":"9653rJJ2xw9k"}},{"cell_type":"code","source":["class DataSet2(torch.utils.data.Dataset):\n","    def __init__(self, dist, shape = (2), total_len = 1000000):\n","        self.dist_mean, self.dist_var, self.dist_num = dist[0], dist[1], dist[2]\n","        self.distribution_list = np.stack([ np.dot([[np.cos(angle), -np.sin(angle)], [np.sin(angle), np.cos(angle)]], dist[0]) for angle in np.linspace(start=0, stop=2 * np.pi, num = dist[2]+1)])\n","        self.shape = shape\n","        self.total_len = total_len\n","        \n","    @property\n","    def _choose_distribution(self):\n","        return int(torch.rand(1) * self.dist_num)\n","        \n","    @property\n","    def _sampling(self):\n","        dist_idx = self._choose_distribution\n","        return torch.from_numpy(self.distribution_list[dist_idx]).float() + torch.randn(self.shape) * self.dist_var\n","\n","\n","    def __len__(self):\n","        return self.total_len\n","    \n","    def __getitem__(self, idx):\n","        data = self._sampling\n","\n","        return data"],"metadata":{"id":"CZLSrEWWxvhy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["eps = 1e-5\n","sigma_min = 0.005\n","sigma_max = 10\n","\n","L = 10\n","T = 100\n","\n","total_iteration = 2000\n","current_iteration = 0\n","display_iteration = 200\n","scatter_range = [-20, 20]\n","\n","batch_size = 8192 * 2\n","\n","dist = [[10,0], 1, 8]\n","dataloader = torch.utils.data.DataLoader(DataSet2(dist, total_len=batch_size * total_iteration), batch_size = batch_size, drop_last = True)\n","\n","\n","sampling_number = 1000\n","device = torch.device('cuda')\n","only_final = True\n","\n","dataiterator = iter(dataloader)\n","\n","model = Model(device, L, sigma_min, sigma_max, p = 0.3)\n","optim = torch.optim.Adam(model.parameters(), lr = 0.002)\n","dynamic = AnnealedLangevinDynamic(sigma_min, sigma_max, L, T, model, device, eps=eps)"],"metadata":{"id":"S7GFJ7-jxyyb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["losses = AverageMeter('Loss', ':.4f')\n","progress = ProgressMeter(total_iteration, [losses], prefix='Iteration ')"],"metadata":{"id":"XszyrFI4x0Ah"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["scatter(next(iter(dataloader)), True, scatter_range)"],"metadata":{"id":"Uc45yJ8Ux1ka"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["while current_iteration != total_iteration:\n","    try:\n","        data = dataiterator.next()\n","    except:\n","        dataiterator = iter(dataloader)\n","        data = dataiterator.next()\n","    data = data.to(device = device)\n","    loss = model.loss_fn(data)\n","\n","    optim.zero_grad()\n","    loss.backward()\n","    optim.step()\n","\n","    losses.update(loss.item())\n","    progress.display(current_iteration)\n","    \n","    current_iteration += 1\n","    \n","    if current_iteration % display_iteration == 0:\n","        dynamic = AnnealedLangevinDynamic(sigma_min, sigma_max, L, T, model, device, eps=eps)\n","        sample = dynamic.sampling(sampling_number, only_final)\n","        scatter(sample, only_final, scatter_range = scatter_range)\n"],"metadata":{"id":"XFKzpGILx3HQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sampling_number = 10000\n","only_final = True\n","dynamic = AnnealedLangevinDynamic(sigma_min, sigma_max, L, T, model, device, eps=eps)\n","sample = dynamic.sampling(sampling_number, only_final)\n","scatter(sample, only_final, scatter_range= scatter_range)"],"metadata":{"id":"OeqjiPBgx4wG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sampling_number = 10000\n","only_final = False\n","dynamic = AnnealedLangevinDynamic(sigma_min, sigma_max, L, T, model, device, eps=eps)\n","sample = dynamic.sampling(sampling_number, only_final)\n","scatter(sample, only_final, scatter_range=scatter_range)"],"metadata":{"id":"rm21zhcEx6F_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def update_plot(i, data, scat):\n","    scat.set_offsets(data[i].detach().cpu().numpy())\n","    return scat\n","\n","numframes = len(sample)\n","scatter_point = sample[0].detach().cpu().numpy()\n","scatter_x, scatter_y = scatter_point[:,0], scatter_point[:,1]\n","\n","fig = plt.figure(figsize=(6, 6))\n","plt.xlim(scatter_range)\n","plt.ylim(scatter_range)\n","scat = plt.scatter(scatter_x, scatter_y, s=1)\n","plt.show()\n","clear_output()\n","\n","ani = animation.FuncAnimation(fig, update_plot, frames=range(numframes), fargs=(sample, scat), interval=150)\n","# ani.save('ncsn_toy2.gif')\n","HTML(ani.to_jshtml())"],"metadata":{"id":"3TXUYA9wx7pE"},"execution_count":null,"outputs":[]}]}